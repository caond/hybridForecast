seed = NULL) {
if (!is.null(seed)) set.seed(seed)
# Parse start date
is_hourly <- freq %in% c("hour", "hours")
start <- if (is_hourly) as.POSIXct(start_date) else as.Date(start_date)
# Generate timestamp sequence
if (is_hourly) {
ds <- seq.POSIXt(from = start, by = freq, length.out = length_out)
} else {
ds <- seq.Date(from = start, by = freq, length.out = length_out)
}
# Seasonal components
seasonal <- matrix(0, nrow = length_out, ncol = length(seasonal_periods))
colnames(seasonal) <- names(seasonal_periods)
for (i in seq_along(seasonal_periods)) {
period <- seasonal_periods[[i]]
seasonal[, i] <- sin(2 * pi * seq_along(ds) / period) * (10 / i)
}
seasonal_total <- rowSums(seasonal)
# Trend component
n_segments <- length(trend_slopes)
change_points <- round(seq(1, length_out, length.out = n_segments + 1))
trend <- numeric(length_out)
for (i in 1:n_segments) {
start <- change_points[i]
end <- change_points[i + 1] - 1
if (i == 1) {
trend[start:end] <- trend_slopes[i] * seq(0, end - start)
} else {
trend[start:end] <- trend[start - 1] + trend_slopes[i] * seq(1, end - start + 1)
}
}
# Noise
noise <- rnorm(length_out, mean = 0, sd = noise_sd)
# Combine
y <- 50 + seasonal_total + trend + noise
data.frame(ds = ds, y = y)
}
smape <- function(a, f) {
a[which(a==Inf)]<- VERY_LARGE
(1/length(a) * sum(2*abs(f-a) / (abs(a+EPSILON)+abs(f+EPSILON))))
}
auto_seasonal_periods <- function(ds, min_obs = 3) {
# ds: vector of Date or POSIXct timestamps
if (length(ds) < min_obs) stop("Not enough data points to detect frequency")
ds <- sort(ds)
diff_days <- as.numeric(median(diff(as.Date(ds)), na.rm = TRUE))
# Define frequency thresholds (in days)
freq <- case_when(
diff_days < 1 ~ "hourly",
diff_days < 2 ~ "daily",
diff_days < 8 ~ "weekly",
diff_days < 31 ~ "monthly",
diff_days < 92 ~ "quarterly",
TRUE ~ "yearly"
)
message("Detected frequency: ", freq)
# Map to seasonal periods
seasonal_periods <- switch(freq,
"hourly" = list(
daily = 24,
weekly = 24 * 7,
yearly = 24 * 365.25
),
"daily" = list(
weekly = 7,
yearly = 365.25
),
"weekly" = list(
yearly = 52
),
"monthly" = list(
yearly = 12,
quarterly = 3
),
"quarterly" = list(
yearly = 4
),
"yearly" = list()  # Usually no seasonality
)
return(seasonal_periods)
}
find_lags<-function(df,max_lag=20)
{
adf_test<-adf.test(df$y)
if (adf_test$p.value>0.05)  y <- diff(df$y)
else y<- df$y
pacf_vals <- pacf(y, lag.max = max_lag, plot = FALSE)
threshold <- 2 / sqrt(length(y))
significant_lags <- which(abs(pacf_vals$acf) > threshold)
significant_lags
}
create_fourier_terms <- function(t, period, prefix, K) {
terms <- list()
for (k in 1:K) {
terms[[paste0(prefix, "_sin", k)]] <- sin(2 * pi * k * t / period)
terms[[paste0(prefix, "_cos", k)]] <- cos(2 * pi * k * t / period)
}
return(as.data.frame(terms))
}
select_changepoints <- function(y, n_changepoints = NA, method = NA) {
n <- length(y)
if (!is.numeric(y)) stop("Input 'y' must be numeric.")
if (is.na(n_changepoints)) {
if (is.na(method)) {
n_changepoints <- min(25, floor(n / 25))
t_range <- 1:floor(0.9 * n)
cps <- quantile(t_range, probs = seq(0.05, 0.95, length.out = n_changepoints))
} else {
# You could allow method selection here
cpt <- changepoint::cpt.meanvar(y, method = method)
cps <- changepoint::cpts(cpt)
}
} else {
t_range <- 1:floor(0.9 * n)
cps <- quantile(t_range, probs = seq(0.05, 0.95, length.out = n_changepoints))
}
return(as.numeric(cps))
}
create_trend_features <- function(n, n_changepoints) {
t <- 1:n
A <- sapply(n_changepoints, function(sj) pmax(0, t - sj))
X <- cbind(t, A)
colnames(X) <- c("t", paste0("cp_", n_changepoints))
return(X)
}
auto_pick_K_all_components <- function(t, seasonal_periods, max_fraction = 0.05, max_K_cap = 5, min_K = 1) {
n <- length(t)
max_total_terms <- floor(n * max_fraction)
sapply(seasonal_periods, function(period) {
n_cycles <- n / period
K <- floor(min(max_total_terms, n_cycles * 2))  # 2 terms per K (sin/cos)
K <- min(K, max_K_cap)
K <- max(K, min_K)
return(K)
})
}
fit_trend_seasonal_model <- function(y,seasonal_periods,n_changepoints,method) {
n <- length(y)
t <- 1:n
# Trend
changepoints <- select_changepoints(y, n_changepoints,method)
trend_X <- create_trend_features(n, changepoints)
# select K
K_list<-auto_pick_K_all_components(t, seasonal_periods)
seasonal_X_list <- lapply(names(seasonal_periods), function(name) {
create_fourier_terms(t, seasonal_periods[[name]], prefix = name, K=K_list[[name]])
})
seasonal_X <- do.call(cbind, seasonal_X_list)
# Combine
X <- cbind(trend_X, seasonal_X)
model <- lm(y ~ . -1, data = data.frame(y = y, X))
betas <- coef(model)
betas <- betas[!is.na(betas)]
trend_vals <- as.vector(as.matrix(trend_X) %*% betas[colnames(trend_X)])
seasonality_outputs <- list()
for (i in seq_along(seasonal_X_list)) {
mat <- as.matrix(seasonal_X_list[[i]])
mat_cols <- colnames(mat)
# Keep only columns that have corresponding non-NA coefficients
valid_cols <- intersect(mat_cols, names(betas))
mat_valid <- mat[, valid_cols, drop = FALSE]
beta_valid <- betas[valid_cols]
# Compute seasonal component for this group
seasonality_outputs[[i]] <- as.vector(mat_valid %*% beta_valid)
}
names(seasonality_outputs)<-names(seasonal_periods)
return(list(
model = model,
changepoints = changepoints,
seasonal_periods = seasonal_periods,
n_train = n,
K_list=K_list, #fourier components
coef_names = colnames(X),
trend=trend_vals,
seasonality=seasonality_outputs
))
}
predict_trend_seasonal_components <- function(model_obj, h) {
n_future <- model_obj$n_train + h
t_pred <- (model_obj$n_train + 1):n_future
# Trend
trend_X <- sapply(model_obj$changepoints, function(sj) pmax(0, t_pred - sj))
trend_X <- cbind(t = t_pred, trend_X)
colnames(trend_X) <- c("t", paste0("cp_", model_obj$changepoints))
# Seasonality
K_list<-model_obj$K_list
season_components <- list()
for (name in names(model_obj$seasonal_periods)) {
season_components[[name]] <- create_fourier_terms(
t_pred, model_obj$seasonal_periods[[name]], prefix = name,K_list[[name]]
)
}
seasonal_X <- do.call(cbind, unname(season_components))
# Full matrix for prediction
full_X <- data.frame(cbind(trend_X, seasonal_X))
preds <- predict(model_obj$model, newdata = full_X)
# Compute each component separately
betas <- coef(model_obj$model)
betas <- betas[!is.na(betas)]
trend_cols <- colnames(trend_X)
component_trend <- as.matrix(trend_X) %*% betas[trend_cols]
component_season <- list()
for (name in names(model_obj$seasonal_periods)) {
# Get seasonal columns with valid coefficients
season_cols <- grep(paste0("^", name, "_"), names(betas), value = TRUE)
# Only keep valid seasonal cols that exist in both matrix and beta
season_cols <- intersect(season_cols, colnames(season_components[[name]]))
if (length(season_cols) > 0) {
season_matrix <- as.matrix(season_components[[name]][, season_cols, drop = FALSE])
component_season[[name]] <- season_matrix %*% betas[season_cols]
} else {
component_season[[name]] <- rep(0, nrow(season_components[[name]]))
}
}
return(list(
forecast = preds,
trend = as.vector(component_trend),
seasonality = component_season,
t = t_pred
))
}
prepare_trend_seasonal_component<-function(train,significant_lags,seasonal_periods,n_changepoints,method)
{
ts_model <- fit_trend_seasonal_model(y=train$y,seasonal_periods=seasonal_periods, n_changepoints=n_changepoints,method=method)
train_feat <- cbind(train, trend = ts_model$trend)
# Add each seasonal component
for (name in names(ts_model$seasonality)) {
train_feat[[name]] <- ts_model$seasonality[[name]]
}
for (i in significant_lags) {
train_feat[[paste0("lag", i)]] <- dplyr::lag(train$y, i)
}
train_feat <- na.omit(train_feat)
return(list(train_feat=train_feat,ts_model=ts_model))
}
predict_one_step <- function(hybrid_model,newdata_feat,xreg) {
n_test <- nrow(newdata_feat)
preds <- list()
use_lags <- length(hybrid_model$significant_lags) > 0
for (model in model_used)
{
browser()
preds[[model]]<-numeric(n_test)
if (use_lags) {
max_lags <- max(hybrid_model$significant_lags)
lag_names <- paste0("lag", hybrid_model$significant_lags)
recent_y <- tail(hybrid_model$train_feat$y, max_lags)
}
for (i in 1:n_test) {
# Prepare lag features
if (use_lags) {
lag_values <- sapply(hybrid_model$significant_lags, function(lag) {
recent_y[length(recent_y) - lag + 1]
})
lag_data<- as.data.frame(as.list(lag_values))
names(lag_data) <- lag_names
input_row <- cbind(newdata_feat[i, c("trend", names(hybrid_model$seasonal_periods))], lag_data)
} else {
input_row <- newdata_feat[i, c("trend", names(hybrid_model$seasonal_periods))]
}
if (!is.na(xreg)) input_row<-cbind(input_row,newdata_feat[i,xreg, drop=FALSE])
preds[[model]][i] <- predict(hybrid_model[[model]], as.matrix(input_row))
# Update recent_y for next iteration
if (use_lags) {
recent_y <- tail(c(recent_y, preds[[model]][i]), max_lags)
}
}
}
return(preds)
}
predict_hybrid_1<-function(hybrid_model,newdata,xreg)
{
# prepare test data with prophet predict on trend and season
res <- predict_trend_seasonal_components(hybrid_model$ts_model, h = NROW(newdata))
newdata_feat <- cbind(newdata, trend = res$trend)
# Add each seasonal component
for (name in names(res$seasonality)) {
newdata_feat[[name]] <- res$seasonality[[name]]
}
# then step by step predict the test
yhat<-predict_one_step(hybrid_model,newdata_feat,xreg)
# Initialize containers
preds <-list()
train <- list()
residuals <- list()
sigma <- list()
yhat_lower <- list()
yhat_upper <- list()
# Forecast horizon and confidence interval setup
h <- NROW(newdata_feat)
ci_scale <- sqrt(1:h)
z <- qnorm(0.975)  # 95% CI
# Models to process
# Generate predictions and compute residuals
for (model in model_used) {
#  train[[model]] <- predict(hybrid_model[[model]], xgb.DMatrix(as.matrix(hybrid_model$train_feat[, hybrid_model$xgb_model$feature_names])))
train[[model]] <- predict(hybrid_model[[model]], as.matrix(hybrid_model$train_feat[,!names(hybrid_model$train_feat) %in% c('ds','y')]))
residuals[[model]] <- hybrid_model$train_feat$y - train[[model]]
sigma[[model]] <- sd(residuals[[model]], na.rm = TRUE)
# Compute confidence intervals for xgb predictions
yhat_lower[[model]] <- yhat[[model]] - z * sigma[[model]] * ci_scale
yhat_upper[[model]] <- yhat[[model]] + z * sigma[[model]] * ci_scale
preds[[model]]$yhat<-yhat[[model]]
preds[[model]]$yhat_lower<-yhat_lower[[model]]
preds[[model]]$yhat_upper<-yhat_upper[[model]]
}
return(preds)
}
#' @method predict hybridForecast_model
#' @export
predict.hybridForecast_model<-function(object,newdata,xreg=NA, ...)
{
test_result<-predict_hybrid_1(object,newdata,xreg)
test_matrix<-do.call(rbind,test_result)
yhat<-do.call(rbind,test_matrix[,'yhat'])
yhat_lower<-do.call(rbind,test_matrix[,'yhat_lower'])
yhat_upper<-do.call(rbind,test_matrix[,'yhat_upper'])
yhat_ensemble<-object$ensemble_weight %*% yhat
yhat_ensemble_lower<-object$ensemble_weight %*% yhat_lower
yhat_ensemble_upper<-object$ensemble_weight %*% yhat_upper
hybrid_forecast<-list()
hybrid_forecast$data<-object$data
hybrid_forecast$emsemble<-object$emsemble
hybrid_forecast$mape<-object$mape
newdata$yhat<-t(yhat_ensemble)
newdata$yhat_lower<-t(yhat_ensemble_lower)
newdata$yhat_upper<-t(yhat_ensemble_upper)
hybrid_forecast$forecast<-newdata
class(hybrid_forecast)<-'hybridForecast'
return(hybrid_forecast)
}
hybrid_core<-function(train, xreg, seasonal_periods,n_changepoints,method,max_lag)
{
if (is.na(xreg)) train<-train[,c('ds','y')]
significant_lags<-find_lags(train,max_lag)
#prepare features
feat_model<-prepare_trend_seasonal_component(train=train,significant_lags=significant_lags,seasonal_periods=seasonal_periods,n_changepoints=n_changepoints,method=method)
train_feat<-feat_model$train_feat
features <- setdiff(colnames(train_feat),c("ds","y"))
#if (!is.na(xreg)) features<-c(features,xreg)
X_train<-train_feat[, features]
y_train <- train_feat$y
## train xgboost model on train
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dtrain_lgb <- lgb.Dataset(data = as.matrix(X_train), label = y_train)
set.seed(123)
xgb_model <- xgb.train(
params = list(
objective = "reg:squarederror",
max_depth = 6,
eta = 0.05,
subsample = 0.8,
colsample_bytree = 0.8,
min_child_weight = 5
),
data = dtrain,
nrounds = 100,
verbose = 0
)
formula_str <- paste("y ~", paste(features, collapse = " + "))
nn_model <- nnet(
formula =as.formula(formula_str),
data=train_feat,
size= max(10, floor(sqrt(NROW(train_feat) / (length(features) + 1)))),
decay = 0.1,
MaxNWts = 5000,
linout = TRUE
)
#lm_model<-lm(as.formula(formula_str),data=train_feat)
lgb_model<-lgb.train(
params =
list(
objective = "regression",
metric = "l2",
learning_rate = 0.05,
num_leaves = 31,
max_depth=-1,
min_data_in_leaf = 20,
feature_fraction = 0.9,
bagging_fraction = 0.8,
bagging_freq = 1
),
data = dtrain_lgb,
nrounds = 100,
verbose = -1
)
return(list(xgb=xgb_model,lgb=lgb_model,nn=nn_model,train_feat=train_feat,significant_lags=significant_lags,seasonal_periods=seasonal_periods,ts_model=feat_model$ts_model))
}
#' @export
hybrid <- function(data,
xreg=NA,
seasonal_periods = NA,
n_changepoints = NA,
method = NA,
max_lag = NA,
horizon = NA,
max_fold = 5) {
N <- nrow(data)
if (is.na(seasonal_periods)) {
seasonal_periods <- auto_seasonal_periods(data$ds)
}
if (is.na(max_lag)) {
baseline_lag <- floor(log(N) * 10)
seasonal_vals <- unlist(seasonal_periods)
seasonal_vals <- seasonal_vals[seasonal_vals < N]
seasonal_lag <- if (length(seasonal_vals) > 0) max(seasonal_vals) else 0
max_lag <- min(max(baseline_lag, seasonal_lag), floor(N / 2))
}
model_choice <- rep(list(0:1), length(model_used))
names(model_choice) <- model_used
combinations <- expand.grid(model_choice) %>% tail(-1) %>% as.matrix()
folds <- vector("list", max_fold)
if (is.na(horizon)) horizon<- min(80,floor(0.2*N))
for (fold in seq_len(max_fold)) {
cat("\nfold", fold)
train_end <- N - horizon - fold + 1
test_range <- (train_end + 1):(train_end + horizon)
train_data <- data[1:train_end, ]
test_data <- data[test_range, ]
hybrid_model <- hybrid_core(train_data,xreg, seasonal_periods,n_changepoints, method, max_lag)
test_result <- predict_hybrid_1(hybrid_model, test_data,xreg)
y <- test_data$y
ds <- test_data$ds
for (model in model_used) {
test_result[[model]]$mape <- smape(y, test_result[[model]]$yhat)
}
# Combine forecasts
test_matrix <- do.call(rbind, test_result)
mape <- do.call(rbind, test_matrix[,"mape"])
yhat <- do.call(rbind, test_matrix[,"yhat"])
yhat_lower <- do.call(rbind, test_matrix[,"yhat_lower"])
yhat_upper <- do.call(rbind, test_matrix[,"yhat_upper"])
weights_matrix <- combinations
for (i in seq_len(nrow(weights_matrix))) {
idx <- which(weights_matrix[i, ] > 0)
inv_mape <- 1 / mape[idx]
inv_mape[!is.finite(inv_mape)] <- 1
weights_matrix[i, idx] <- inv_mape
weights_matrix[i, ] <- weights_matrix[i, ] / sum(weights_matrix[i, ])
rownames(weights_matrix)[i] <- paste(model_used[idx], collapse = "|")
}
yhat_ensemble <- weights_matrix %*% yhat
yhat_ensemble_lower <- weights_matrix %*% yhat_lower
yhat_ensemble_upper <- weights_matrix %*% yhat_upper
mape_by_method<-apply(yhat_ensemble,1,function(fcst){ smape(fcst,y)})
folds[[fold]] <- list(
y = y, ds = ds,
yhat_ensemble = yhat_ensemble,
yhat_ensemble_lower = yhat_ensemble_lower,
yhat_ensemble_upper = yhat_ensemble_upper,
mape_by_method = mape_by_method,
combinations = weights_matrix
)
}
# Combine folds
mape_matrix <- do.call(cbind, lapply(folds, `[[`, "mape_by_method"))
mean_mape <- rowMeans(mape_matrix)
best_idx <- which.min(mean_mape)
best_method <- names(mean_mape)[best_idx]
best_mape <- mean_mape[best_idx]
all_combinations <- do.call(rbind, lapply(folds, `[[`, "combinations"))
best_weights <- colMeans(all_combinations[rownames(all_combinations) == best_method, , drop = FALSE])
yhat_all <- do.call(cbind, lapply(folds, `[[`, "yhat_ensemble"))
yhat_all_lower <- do.call(cbind, lapply(folds, `[[`, "yhat_ensemble_lower"))
yhat_all_upper <- do.call(cbind, lapply(folds, `[[`, "yhat_ensemble_upper"))
ds_all <- do.call(c,lapply(folds, `[[`, "ds"))
y_all <- unlist(lapply(folds, `[[`, "y"))
mape_all <- rep(mape_matrix[best_method, ], each = horizon)
cv_data <- data.frame(
fold = rep(1:max_fold, each = horizon),
ds = ds_all,
y = y_all,
yhat = yhat_all[rownames(yhat_all) == best_method, ],
yhat_lower = yhat_all_lower[rownames(yhat_all_lower) == best_method, ],
yhat_upper = yhat_all_upper[rownames(yhat_all_upper) == best_method, ],
mape = mape_all
) %>% group_by(fold) %>% mutate(fold_label = paste0("Fold ", fold, " (MAPE = ", round(mape[1] * 100, 1), "%)"))
# Refit on full data
final_model <- hybrid_core(data, xreg, seasonal_periods,n_changepoints, method, max_lag)
final_model$data<-data
final_model$cv_data <- cv_data
final_model$mape <- best_mape
final_model$ensemble_weight <- best_weights
final_model$emsemble <- best_method
class(final_model)<-'hybridForecast_model'
return(final_model)
}
data
hybrid_model <- hybrid(data,xreg='pop')
library(dplyr)
library(xgboost)
hybrid_model <- hybrid(data,xreg='pop')
library(tseries)
hybrid_model <- hybrid(data,xreg='pop')
library(lightgbm)
hybrid_model <- hybrid(data,xreg='pop')
library(nnet)
hybrid_model <- hybrid(data,xreg='pop')
preds[[model]]
input_row
hybrid_model[[model]]$feature_names
as.matrix(input_row)
predict(hybrid_model[[model]], as.matrix(input_row))
input_row <- cbind(newdata_feat[i, c("trend", names(hybrid_model$seasonal_periods))], lag_data)
input_row<-cbind(newdata_feat[i,xreg, drop=FALSE],input_row)
predict(hybrid_model[[model]], as.matrix(input_row))
remove.packages('hybridForecast')
devtools::document()
devtools::document()
remove.packages('hybridForecast')
devtools::document()
